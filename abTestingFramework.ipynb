{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ea2bd5a-2c7f-4ebe-a672-e60c136f9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from statsmodels.stats.weightstats import ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d56b92-fb27-48c7-a279-350ffa66ca2b",
   "metadata": {},
   "source": [
    "# AB Testing Done right\n",
    "\n",
    "Based on the data type you want to analyse and your sample size,\n",
    "the tests to apply changes. In the following we'll show you how to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a2ede-c9dd-4a13-ada4-ba12404c196b",
   "metadata": {},
   "source": [
    "## Computing sample size and duration based on significance lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce54ddc-549c-4e6d-a76c-f27fe24dd858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# current (base) mean recorded (ex: convertion rate)\n",
    "current_conv_rate =  0.1\n",
    "std_dev = 1\n",
    "# desired uplift:  the minimum detectable effect or minimum effect size (in pct of base rate)\n",
    "desired_uplift = 0.5 # expected: current_conv_rate+ current_conv_rate*desired_uplift\n",
    "# statistical power \"1-β\" is used to represent statistical power, where β (beta) is the probability of failing to reject the null hypothesis when it is false.\n",
    "statistical_p = 0.8\n",
    "\n",
    "# probability of rejecting the null hypothesis when it is true\n",
    "alpha = 0.05\n",
    "#how confident we are with the results\n",
    "confidence_level = 1-alpha\n",
    "\n",
    "#one sided or two sided (only above some threshold or above and below): \n",
    "side = 2\n",
    "\n",
    "# number of events currently happening (and expected to happen)\n",
    "number_of_events_per_weeek = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c99dc2-6160-40e5-901e-9a89f1ab2b68",
   "metadata": {},
   "source": [
    "#### Sample size needed for comparing the means of two normally distributed samples :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93f0356-d28e-4e83-85b8-df93efa19bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events needed per group: 6279.103787479269\n",
      "Number of weeks needed: 6.2791037874792694\n"
     ]
    }
   ],
   "source": [
    "# normal z-value for significance lvl alpha = 0.05\n",
    "Za = norm.ppf(1-alpha/side)\n",
    "# normal z-value for the power of 80% \n",
    "Zb = norm.ppf(statistical_p)\n",
    "\n",
    "n = np.power(Za+Zb,2)*2*(std_dev)**2 / ( (current_conv_rate*(desired_uplift))**2)\n",
    "print(f'Number of events needed per group: {n}')\n",
    "print(f'Number of weeks needed: {n/number_of_events_per_weeek}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951f25f-a250-4487-bb1a-3a9575cc9740",
   "metadata": {},
   "source": [
    "#### Sample size needed for comparing the means of two binomial proportions using a two sided test:\n",
    "( for un balanced samples check: https://towardsdatascience.com/required-sample-size-for-a-b-testing-6f6608dd330a ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d688087-d24f-4321-ae42-592710078cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import zt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportion_effectsize as es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "798a549a-c2e4-4e74-9432-6504c48935e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of events needed per group: 680.3526619127882\n",
      "Number of weeks needed: 0.6803526619127882\n"
     ]
    }
   ],
   "source": [
    "n = zt_ind_solve_power(effect_size=es(prop1=current_conv_rate, prop2=current_conv_rate+current_conv_rate*desired_uplift), alpha=alpha, power=statistical_p, alternative=\"two-sided\")\n",
    "print(f'Number of events needed per group: {n}')\n",
    "print(f'Number of weeks needed: {n/number_of_events_per_weeek}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812df33-7ddf-4d37-97fe-1fa11936df77",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing the data\n",
    "\n",
    "We assume that you want to compare two samples. \n",
    "\n",
    "One from the Base cohort (control) and the second one from the tested cohort (variant).\n",
    "\n",
    "You can either choose to imput the full random variable produced by both cohorts or only provide the mean, std and number of sample in both cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf191bc-3185-4d90-b6c2-496e70ca3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow to compute the various metrics provided in the df\n",
    "def compute_sample_stat(df):\n",
    "        \n",
    "    return df.mean(),df.std(),len(df), df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22782b4b-6f44-40d6-b34a-4bd06a2b7699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.641414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.123917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.118917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.554669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_fees\n",
       "0    2.641414\n",
       "1    0.000000\n",
       "2    1.123917\n",
       "3    9.118917\n",
       "4    4.554669"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing full samples\n",
    "# each row being a costumer using the app with buy incentive to buy in game accesories activated or not activated\n",
    "df_control = pd.read_csv('amount_spent_in_game_no_ads.csv',index_col=0)\n",
    "df_variant = pd.read_csv('amount_spent_in_game_ads_activated.csv',index_col=0)\n",
    "\n",
    "mean_c, std_c, N_c, metrics = compute_sample_stat(df_control)\n",
    "mean_v, std_v, N_v, metrics = compute_sample_stat(df_variant)\n",
    "\n",
    "df_variant.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecc651d2-9839-4e81-85bd-17153a2b95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plugging mean and std\n",
    "\n",
    "#mean_c, std_c, N_c = 1,1,1\n",
    "#mean_v, std_v, N_v = 1,1,1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e39bef-78b4-4f62-8ff1-b4bdf04de0db",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setting up hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b7aa22-2b62-439a-b842-fdda737d47e4",
   "metadata": {},
   "source": [
    "standard formulation is to set:\n",
    "- H_0: null hypothesis as the equality hypothesis\n",
    "- H_1: negates the null hypothesis\n",
    "\n",
    "\n",
    "The alternative hypothesis can be directional or non-directional. The hypothesis is directional when the alternative hypothesis defines an orientation, either greater than (>) or less than (<) that established in the null hypothesis.\n",
    "\n",
    "On the other hand, the hypothesis is non-directional when the alternative hypothesis does not define an orientation explicitly, that is, it only determines that the hypothesis is different from the null hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1200c74e-7781-4c03-8959-932a0b53a478",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "*Significance level*\n",
    "\n",
    "To check if the statement in the null hypothesis is correct, we need to define a significance level. Commonly, the significance level is 5% and is interpreted as follows: if the probability of our sample mean is less than or equal to 5%, then the null hypothesis is rejected, on the other hand, if the probability of our sample mean is greater than 5%, then the null hypothesis remains or fails to be rejected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33bef0a4-d6bd-467f-843e-bbed62f9b4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05 # significance lvl 5%\n",
    "if side == 2:\n",
    "    directional = False\n",
    "else:\n",
    "    directional = True  # see above for definition\n",
    "\n",
    "if directional:\n",
    "    alpha_value = alpha\n",
    "else: \n",
    "    alpha_value = alpha /2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f44e3-318e-4f39-9a65-c45f519e78a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Choosing a test (for continous data)\n",
    "\n",
    "Depending the number of samples, types of hypothesis (directional / non directional ) and the data distribution, a different test will be chosen.\n",
    "\n",
    "We also need to define the alpha / significance threshold that we can accept (as maximum likelihood to see H0 and still reject it).\n",
    "\n",
    "Then the final choice is taken using the p-value (probability of occurence of H0). The lower it is, the more confident we can be in rejecting H₀.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f0fcd6-f246-4b0b-b234-463e91f95ef0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### if N>30 and continuous value testing: Z test\n",
    "\n",
    "\n",
    "H₀: the average \"fees generated\" is the same for the two versions\n",
    "\n",
    "\n",
    "H₁: the average \"fees generated\" is higher for version B\n",
    "\n",
    "\n",
    " If we know the mean and the variance, the z-test would be the most appropriate option.\n",
    "\n",
    "We recall that for N>30 the law of large number applies and the mean behaves as a normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c0768-2b5a-4430-a7bf-5039a231929e",
   "metadata": {},
   "source": [
    "Conceptually, Z represents the number of standard deviations the observed difference of means is away from 0. The higher this number, the lesser the likelihood of H₀.\n",
    "\n",
    "\n",
    "From the formula of Z, you can also get the intuition that the smaller the difference to prove is, the more samples you need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a84cad-82af-464a-ab65-41ba197261bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "This z-score gives us the number of standard deviations at which a sample mean is found concerning the population mean.\n",
    "\n",
    "all the values of the sample mean concerning the population mean are normally distributed, therefore, at least 95% of all the sample means fall within 2 standard deviations of the population mean, that is, there is less than 5% probability of obtaining a sample mean beyond 2 standard deviations of the population mean.\n",
    "\n",
    "Then, if the probability of occurrence (or p-value) is less than or equal to 5%, the null hypothesis is rejected, on the other hand, if the probability of occurrence (or p-value) is greater than 5%, the null hypothesis is retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e2f4dd-eb20-4b87-b6cd-76ab6fe23ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_fees    5.589856\n",
      "dtype: float64\n",
      "total_fees    6.362558\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(mean_c)\n",
    "print(mean_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cdeed-b6b5-4aea-ba21-42170f2a1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = (mean_v - mean_c)/np.sqrt(std_v**2/N_v + std_c**2/N_c)\n",
    "pvalue = 1-norm.cdf(Z)\n",
    "\n",
    "print(\"Z-score: {0}\\np-value: {1}\".format(Z.values,pvalue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38594a2f-43f0-4c3d-88ed-9ddd2248d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3e792-6824-4040-9ffb-444fa8c9bed1",
   "metadata": {},
   "source": [
    "the critical values (areas under the curve) for the Z test are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9863c-84f9-435d-aa01-47c2b3c4a43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(alpha_value)\n",
    "reject1 = norm.ppf(1-alpha_value)\n",
    "print(reject1)\n",
    "if not directional:\n",
    "    reject2 = norm.ppf(alpha_value)\n",
    "    print(reject2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1b6004-5c49-4150-a5d4-e197d87089e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Zvalue: {Z.values}')\n",
    "proba_outside = 1-norm.cdf(Z)\n",
    "if not directional:\n",
    "    proba_outside = proba_outside* 2\n",
    "print(f'Proba to be above Z: {proba_outside}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe3074a-98d8-4cfb-821b-bd92d2f02cb1",
   "metadata": {},
   "source": [
    "we find that the probability of observing a standard normal value below 0.9975 is approximately 0.69 ( or norm.cdf(Z) ) . \n",
    "http://www.z-table.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20140458-a1af-4176-962b-ef4fa889a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04197d7-a3c0-4319-ace1-80b8e4835a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b5179b-d5f6-47aa-be22-a0c65291981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.arange(-3, 3, 0.1)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace( go.Scatter(x = z, y =norm.pdf(z),  mode='lines',name = 'probability distribution'))\n",
    "fig.add_trace(go.Scatter(x=z[z>Z.total_fees], y= norm.pdf(z[z>Z.total_fees]), fill='tozeroy', mode='none', name = 'Empirical value')) \n",
    "fig.add_trace(go.Scatter(x=[reject1, reject1], y=[0,0.4], mode=\"lines\", name=\"rejection line\", marker_color = 'red')) \n",
    "if not directional:\n",
    "    fig.add_trace(go.Scatter(x=[reject2, reject2], y=[0,0.4], mode=\"lines\",  name=\"rejection line\", marker_color = 'red', showlegend=False)) \n",
    "\n",
    "fig.update_layout(\n",
    "    title=r\" $\\text{Normal PDF and rejection lines for } \\alpha=  %s$\"% (alpha),\n",
    "    xaxis_title=\"X\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    legend_title=\"\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779757ca-d897-42c1-af00-58795dbfb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "if proba_outside>alpha:\n",
    "    print('Cannot reject H0, the proba to be inside is too high')\n",
    "else:\n",
    "    print(f'We reject H0 in favor of H1 with level of significance {alpha*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18587a8-38d7-4225-af49-8532931641ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "### N<30: student t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b516afff-1c09-4b1f-9b00-cad7ba0995c1",
   "metadata": {},
   "source": [
    "- one sample t-test: if we have only the mean of a sample A and want to compare to the \"population mean\" or just a value\n",
    "- two sample t-test: we compare the means of the two samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783cb9b-40ab-405a-be75-d235eefc6182",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "- H0 : population mean is greater or equal to sample mean (μ> = x)\n",
    "- H1 : population mean is less than sample mean (μ< x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc3a9f-d060-4be0-b916-412419c51745",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-alpha_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6774d2b-5ca9-4df9-afab-8021355b05e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate t statistics\n",
    "# here we consider mean_c as the population mean\n",
    "t = abs(mean_c - mean_v) / std_v\n",
    "print('t static:',t)\n",
    "# two-tailed critical value at alpha = 0.05\n",
    "# df = degree of freedoms ( nb of samples -1 )\n",
    "t_crit = stats.t.ppf(q=1-alpha_value, df= len(df_variant)-1)\n",
    "print(\"Critical value for t two tailed:\",t_crit)\n",
    "\n",
    "#get two-tailed p value\n",
    "p_value = 2*(1-stats.t.cdf(x=t, df=len(df_variant)-1))\n",
    "print(\"p-value:\",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25ee88-be61-4b79-a94d-393bb017ea58",
   "metadata": {},
   "source": [
    "### One tailed (side =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9863e6fa-1160-476b-b67b-e2232a60e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-tailed critical value at alpha = 0.05\n",
    "t_crit = stats.t.ppf(q=1-alpha_value, df=len(df_variant)-1)\n",
    "print(\"Critical value for t one tailed:\",t_crit)\n",
    "\n",
    "\n",
    "# get one-tailed p value\n",
    "p_one = 1-stats.t.cdf(x=t, df=len(df_variant)-1)\n",
    "print(\"p-value for one tailed:\",p_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424e7118-5cfc-4ac2-a788-459439ef7a67",
   "metadata": {},
   "source": [
    " we cannot reject H0 if p> 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e517078-f176-4618-aac5-811c669338db",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2 tailed (side = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2462201-be4a-45f8-9470-5575ba2189a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooled sample variance\n",
    "var = ( ((N_v-1)*std_v**2) + ((N_c-1)*std_c**2) ) / (N_v+N_c-2)\n",
    "std_error = np.sqrt(var * (1.0 / N_v + 1.0 / N_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8c9179-acb0-43db-be3e-24b6deb480c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = abs(mean_c - mean_v) / std_error\n",
    "print('t static:',t)\n",
    "# two-tailed critical value at alpha = 0.05\n",
    "t_c = stats.t.ppf(q=1-alpha_value, df=max(N_v,N_c))\n",
    "print(\"Critical value for t two tailed:\",t_c)\n",
    "\n",
    "#get two-tailed p value\n",
    "p_value = 2*(1-stats.t.cdf(x=t, df=max(N_v,N_c)))\n",
    "print(\"p-value:\",p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c6d6e5-33b9-4fe5-9ed6-18f0e78e68e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Non inferiority testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a5d25-a7d2-4123-90d6-df2333feabe0",
   "metadata": {},
   "source": [
    "The error we want to avoid the most is the error of failing to implement a new solution, which is about equal, or better than what we currently have.\n",
    "\n",
    "decision about a noninferiority margin should be made. A noninferiority margin is such a negative difference, or relative difference, that can be tolerated while still considering the performance of the control and variant about the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e597a673-4e8b-42aa-8c6f-18e367500970",
   "metadata": {},
   "source": [
    "Null hypothesis:  variant(s) < control or more precisely variant(s) < control – δ\n",
    "\n",
    "the varient is worse than the control and some tolerance threshold\n",
    "\n",
    "\n",
    "Using the degree of freedom and the level of significance, one can get minimum t value to have ( if greater we can rejet h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe83364-9c21-45f1-91ea-448f4e034d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_inferiority_ttest(sample1, sample2, relative_difference, equal_variance=False,\n",
    "                          increase_good=True):\n",
    "    '''\n",
    "    Perform a one-sided t-test with a non-inferiority threshold for two independent samples.\n",
    "    mean1/2: group mean\n",
    "    stddev1/2: standard deviation of each group\n",
    "    n1/2: number of observations in each group\n",
    "    relative_difference: threshold as a percentage of the base group (e.g. 0.1=10% difference)\n",
    "    equal_variance: if False, uses Welch's t-test.\n",
    "    \n",
    "    \n",
    "    increase_good: if True, Ho: mean2 <= mean1 - threshold. Else Ho: mean2 >= mean1 + threshold.\n",
    "    Returns: \n",
    "    '''\n",
    "    mean1 = sample1.mean()\n",
    "    stddev1 = sample1.std()\n",
    "    n1 = len(sample1)\n",
    "    \n",
    "    mean2 = sample2.mean()\n",
    "    stddev2 = sample2.std()\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    delta = relative_difference * mean1\n",
    "\n",
    "    if increase_good:\n",
    "        threshold = mean1 - delta\n",
    "    else:\n",
    "        threshold = mean1 + delta\n",
    "    \n",
    "    print('threshold:',threshold)\n",
    "    print('variant mean:',mean2)\n",
    "    \n",
    "    \n",
    "    #ttest_ind_from_stats\n",
    "    if len(sample1)>30:\n",
    "        stat = (mean2 - threshold)/np.sqrt(stddev2**2/n2 + stddev1**2/n1)\n",
    "        if increase_good:\n",
    "            pvalue = 1-norm.cdf(stat)\n",
    "        else:\n",
    "            pvalue = norm.cdf(stat)\n",
    "            \n",
    "        print(\"Z-score: {0}\\np-value: {1}\".format(stat,pvalue))\n",
    "   \n",
    "        \n",
    "    else:\n",
    "        stat, pval = stats.ttest_ind_from_stats(mean1=threshold, \n",
    "                                       std1=stddev1, \n",
    "                                       nobs1=n1, \n",
    "                                       mean2=mean2, \n",
    "                                       std2=stddev2, \n",
    "                                       nobs2=n2, \n",
    "                                       equal_var=equal_variance)\n",
    "        if increase_good:\n",
    "            pvalue = pval/2\n",
    "        else:\n",
    "            pvalue = 1 - pval/2.0\n",
    "        \n",
    "    \n",
    "    return stat, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb822c3-737b-4068-9d60-8d5a787c355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('control mean: ',df_control['total_fees'].mean() ) \n",
    "print('variant mean: ',df_variant['total_fees'].mean() ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abe1f03-a701-49d5-8d5b-e65a8467cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#H0: mean_v <= mean_c - treshold\n",
    "t_val,p_val = non_inferiority_ttest(df_control['total_fees'],df_variant['total_fees'],\n",
    "                                    relative_difference=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6fc0fd-6677-4418-8499-80a74499b8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_val < alpha:\n",
    "    print(f'we can safely (alpha = {alpha}%) reject h0 with pval = {p_val}')\n",
    "else:\n",
    "    print('we cannot reject h0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462dc605-6668-4130-8afc-c54085756b45",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing binary results: (converted / not converted)\n",
    "\n",
    "example with random data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c603b-cb96-4b47-8633-1befb2ce9adf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Chi test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5325b-7692-4a19-b2f3-49f92c732977",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Modelling H_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e31fe63-cba8-4135-9c39-263aa858d804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# H0 assumes that we have same conversion:\n",
    "\n",
    "total_control = 21405\n",
    "converted_control = 3349\n",
    "not_converted_control = total_control - converted_control\n",
    "\n",
    "\n",
    "total_variant = 19177\n",
    "converted_variant_o = total_variant*converted_control/total_control\n",
    "not_converted_variant_o = total_variant - converted_variant_o\n",
    "\n",
    "\n",
    "O =np.array([total_control,converted_variant_o,\n",
    "              not_converted_control,not_converted_variant_o])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442a437e-fedc-419b-8e48-24a1be934df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(converted_variant_o+converted_control)/ ( total_control+total_variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af37eb46-b5ec-42f2-b581-ba2bb858b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion data:\n",
    "# H1:\n",
    "\n",
    "total_control = 21405\n",
    "converted_control = 3349\n",
    "not_converted_control = total_control - converted_control\n",
    "\n",
    "total_variant = 19177\n",
    "converted_variant = 3102\n",
    "not_converted_variant = total_variant - converted_variant\n",
    "\n",
    "\n",
    "T = np.array([total_control,converted_variant,\n",
    "              not_converted_control,not_converted_variant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4895bd-7cad-496a-9d2f-7c648e4e541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(converted_variant+converted_control)/ ( total_control+total_variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67557b40-67d3-4a35-87b0-64f0e42c2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = np.sum(np.square(T-O)/T)\n",
    "pvalue = chi2.sf(D, df=1)\n",
    "\n",
    "print(\"distance d: {0}\\np-value: {1}\".format(D,pvalue))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab0f978-89e7-49a4-9862-c8722ecae2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.arange(0, 5, 0.1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = d, y = chi2.pdf(d, df=1),  mode='lines',name = 'probability distribution'))\n",
    "fig.add_trace(go.Scatter(x=d[d>D], y= chi2.pdf(d[d>D], df=1), fill='tozeroy', mode='none', name = 'Empirical value'))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=r\" $\\text{Chi-squared distribution 1 degree for } \\alpha=  %s$\"% (alpha),\n",
    "    xaxis_title=r\"$X^2$\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    legend_title=\"\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec17d65-7b04-4a97-9ce8-1f12e5b9ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if converted_variant>converted_variant_o and pvalue<0.05:\n",
    "    print('we can safely reject H0 and conclude that there is an increase in conversion')\n",
    "    \n",
    "elif converted_variant<converted_variant_o and pvalue<0.05:\n",
    "    print('we can safely reject H0 and conclude that there is an reduction in conversion')\n",
    "    \n",
    "else:\n",
    "    print('we cannot reject H0, same conversion')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ada37a-8d2f-4adb-8e00-0dfc6459ebd4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Z test adapted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b6248d-b655-4cc0-9b67-58c6b039c8d6",
   "metadata": {},
   "source": [
    " We can use the moment of the binomial distribution to perform a similar test that was done on the normal distribution in step 1. Following the large number, as we get more data the results should converge towards the one of the Chi-square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be280abd-cdc4-4057-8cfc-f60d2042e862",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_c = converted_control/total_control\n",
    "std_c = mean_c * (1-mean_c)\n",
    "N_c = total_control\n",
    "\n",
    "mean_v = converted_variant/total_variant\n",
    "std_v = mean_v * (1-mean_v)\n",
    "N_v = total_variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadf088-9864-4007-b04a-67e4ddc61df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = (mean_v - mean_c)/np.sqrt(std_v**2/N_v + std_c**2/N_c)\n",
    "pvalue = norm.sf(Z)\n",
    "z = np.arange(-3, 3, 0.1)\n",
    "\n",
    "print(\"Z-score: {0}\\np-value: {1}\".format(Z,pvalue))\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x = z, y = norm.pdf(z),  mode='lines',name = 'probability distribution'))\n",
    "fig.add_trace(go.Scatter(x=z[z>Z], y= norm.pdf(z[z>Z]), fill='tozeroy', mode='none', name = 'Empirical value'))\n",
    "#fig.add_trace(go.Scatter(x=[reject1, reject1], y=[0,0.4], mode=\"lines\", name=\"rejection line\", marker_color = 'red')) \n",
    "#if not directional:\n",
    " #   fig.add_trace(go.Scatter(x=[reject2, reject2], y=[0,0.4], mode=\"lines\",  name=\"rejection line\", marker_color = 'red', showlegend=False)) \n",
    "\n",
    "fig.update_layout(\n",
    "    title=r\" $\\text{Normal distribution for } \\alpha=  %s$\"% (alpha),\n",
    "    xaxis_title=r\"$X$\",\n",
    "    yaxis_title=\"Probability Density\",\n",
    "    legend_title=\"\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=18,\n",
    "        color=\"RebeccaPurple\"\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed99ff-69f9-4ec7-9ce8-a003bbdb429a",
   "metadata": {},
   "source": [
    " the z test might lead to slightly different results in that case and the Xi test should be preferred.\n",
    " \n",
    " This difference may be explained by a slight weakness of the Z-test, which does not acknowledge here the binary nature of the rv: μ(B)-μ(A) is actually bounded in [-1,1] and the observation is therefore attributed a lower p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da93b460-cdb8-42f6-b835-8a568ff0e84d",
   "metadata": {},
   "source": [
    "## Online tools:\n",
    "- https://cxl.com/ab-test-calculator/ (one sided sample size calculator) \n",
    "- https://www.evanmiller.org/ab-testing/sample-size.html#\n",
    "- https://www.stat.ubc.ca/~rollin/stats/ssize/n2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b16c1-e089-41f4-a61e-242bf0e9dcf4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e24ae51-3dcb-429d-9f74-41f4f53eba16",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Ztest, hypothesis and directionnality https://towardsdatascience.com/hypothesis-testing-z-scores-337fb06e26ab \n",
    "- statistical significance https://towardsdatascience.com/statistical-significance-hypothesis-testing-the-normal-curve-and-p-values-93274fa32687 \n",
    "- non-inferiority testing https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2701110/pdf/nihms112245.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ba2e5-b411-4bc7-bd02-515c6d5548a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
